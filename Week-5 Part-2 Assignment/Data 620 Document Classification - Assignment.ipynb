{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Austin Chan, Justin Herman, Chester Poon, Deepak Mongia, Michael O'Donnell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a part of this assignment, we are working on a given data set which is a set of emails with the frequencies given for various words and strings for 4601 emails, and a class which suggests whether a particular email is a spam or ham (non-spam).\n",
    "Data source is: http://archive.ics.uci.edu/ml/datasets/Spambase\n",
    "\n",
    "As a part of this assignment, we will use this data set, and divide it into training and test data set. We will build a classifier, fit it using the training data, and evaluate it using the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the field names from the file \"spambase.names\"\n",
    "\n",
    "names_list = []\n",
    "\n",
    "with open(\"spambase.names\") as f:\n",
    "    for line in f:\n",
    "        if not line.startswith((\"|\",\"1\",\"\\n\")):\n",
    "            names_list.append(line.split(\":\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding spamclass to the field names, so it can be used to name the columns for the dataframe\n",
    "\n",
    "names_list.append(\"spamclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the file \"spambase.data\" to get the data\n",
    "\n",
    "data_df = pd.read_csv(\"spambase.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the dataframe columns to relevant names from the other file\n",
    "\n",
    "data_df.columns = names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0               0.00               0.64           0.64           0.0   \n",
      "1               0.21               0.28           0.50           0.0   \n",
      "2               0.06               0.00           0.71           0.0   \n",
      "3               0.00               0.00           0.00           0.0   \n",
      "4               0.00               0.00           0.00           0.0   \n",
      "5               0.00               0.00           0.00           0.0   \n",
      "6               0.00               0.00           0.00           0.0   \n",
      "7               0.00               0.00           0.00           0.0   \n",
      "8               0.15               0.00           0.46           0.0   \n",
      "9               0.06               0.12           0.77           0.0   \n",
      "10              0.00               0.00           0.00           0.0   \n",
      "11              0.00               0.00           0.25           0.0   \n",
      "12              0.00               0.69           0.34           0.0   \n",
      "13              0.00               0.00           0.00           0.0   \n",
      "14              0.00               0.00           1.42           0.0   \n",
      "15              0.00               0.42           0.42           0.0   \n",
      "16              0.00               0.00           0.00           0.0   \n",
      "17              0.00               0.00           0.00           0.0   \n",
      "18              0.00               0.00           0.55           0.0   \n",
      "19              0.00               0.63           0.00           0.0   \n",
      "20              0.00               0.00           0.00           0.0   \n",
      "21              0.05               0.07           0.10           0.0   \n",
      "22              0.00               0.00           0.00           0.0   \n",
      "23              0.00               0.00           0.00           0.0   \n",
      "24              0.00               0.00           0.00           0.0   \n",
      "25              0.05               0.07           0.10           0.0   \n",
      "26              0.00               0.00           0.00           0.0   \n",
      "27              0.00               0.00           0.00           0.0   \n",
      "28              0.00               0.00           0.00           0.0   \n",
      "29              0.00               0.00           0.00           0.0   \n",
      "...              ...                ...            ...           ...   \n",
      "4571            0.00               0.00           0.46           0.0   \n",
      "4572            0.00               0.00           0.00           0.0   \n",
      "4573            0.00               0.00           0.18           0.0   \n",
      "4574            0.29               0.00           0.29           0.0   \n",
      "4575            0.00               0.00           0.00           0.0   \n",
      "4576            0.00               0.00           0.00           0.0   \n",
      "4577            0.00               0.00           1.20           0.0   \n",
      "4578            0.00               0.00           0.40           0.0   \n",
      "4579            0.27               0.05           0.10           0.0   \n",
      "4580            0.00               0.00           0.00           0.0   \n",
      "4581            0.00               0.00           0.00           0.0   \n",
      "4582            0.00               0.00           0.00           0.0   \n",
      "4583            0.00               0.00           1.23           0.0   \n",
      "4584            0.00               0.00           0.45           0.0   \n",
      "4585            0.00               0.00           0.00           0.0   \n",
      "4586            0.00               0.00           0.00           0.0   \n",
      "4587            0.00               0.00           0.00           0.0   \n",
      "4588            0.00               0.00           3.03           0.0   \n",
      "4589            0.00               0.00           0.00           0.0   \n",
      "4590            0.00               0.00           0.00           0.0   \n",
      "4591            0.00               0.00           0.00           0.0   \n",
      "4592            0.00               0.00           1.25           0.0   \n",
      "4593            0.00               0.00           0.00           0.0   \n",
      "4594            0.00               0.00           0.00           0.0   \n",
      "4595            0.00               0.00           1.19           0.0   \n",
      "4596            0.31               0.00           0.62           0.0   \n",
      "4597            0.00               0.00           0.00           0.0   \n",
      "4598            0.30               0.00           0.30           0.0   \n",
      "4599            0.96               0.00           0.00           0.0   \n",
      "4600            0.00               0.00           0.65           0.0   \n",
      "\n",
      "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0              0.32            0.00              0.00                0.00   \n",
      "1              0.14            0.28              0.21                0.07   \n",
      "2              1.23            0.19              0.19                0.12   \n",
      "3              0.63            0.00              0.31                0.63   \n",
      "4              0.63            0.00              0.31                0.63   \n",
      "5              1.85            0.00              0.00                1.85   \n",
      "6              1.92            0.00              0.00                0.00   \n",
      "7              1.88            0.00              0.00                1.88   \n",
      "8              0.61            0.00              0.30                0.00   \n",
      "9              0.19            0.32              0.38                0.00   \n",
      "10             0.00            0.00              0.96                0.00   \n",
      "11             0.38            0.25              0.25                0.00   \n",
      "12             0.34            0.00              0.00                0.00   \n",
      "13             0.90            0.00              0.90                0.00   \n",
      "14             0.71            0.35              0.00                0.35   \n",
      "15             1.27            0.00              0.42                0.00   \n",
      "16             0.94            0.00              0.00                0.00   \n",
      "17             0.00            0.00              0.00                0.00   \n",
      "18             1.11            0.00              0.18                0.00   \n",
      "19             1.59            0.31              0.00                0.00   \n",
      "20             0.00            0.00              0.00                0.00   \n",
      "21             0.76            0.05              0.15                0.02   \n",
      "22             2.94            0.00              0.00                0.00   \n",
      "23             1.16            0.00              0.00                0.00   \n",
      "24             0.00            0.00              0.00                0.00   \n",
      "25             0.76            0.05              0.15                0.02   \n",
      "26             0.00            0.00              0.00                0.00   \n",
      "27             0.00            0.00              1.66                0.00   \n",
      "28             0.00            0.00              0.00                0.00   \n",
      "29             0.65            0.00              0.65                0.00   \n",
      "...             ...             ...               ...                 ...   \n",
      "4571           0.23            0.23              0.00                0.00   \n",
      "4572           0.00            0.00              0.00                0.00   \n",
      "4573           0.18            0.18              0.00                0.00   \n",
      "4574           0.00            0.00              0.00                0.00   \n",
      "4575           0.00            0.00              0.00                0.00   \n",
      "4576           0.00            0.00              0.00                0.00   \n",
      "4577           0.00            0.00              0.00                0.00   \n",
      "4578           0.00            0.00              0.00                0.00   \n",
      "4579           0.00            0.00              0.00                0.00   \n",
      "4580           0.00            0.00              0.00                0.00   \n",
      "4581           0.00            0.51              0.00                0.00   \n",
      "4582           0.00            0.00              0.00                0.00   \n",
      "4583           0.00            0.00              0.00                0.00   \n",
      "4584           0.00            0.22              0.00                0.00   \n",
      "4585           0.00            0.00              0.00                0.00   \n",
      "4586           0.36            0.00              0.00                0.00   \n",
      "4587           0.00            0.00              0.00                0.00   \n",
      "4588           0.00            0.00              0.00                0.00   \n",
      "4589           0.54            0.00              0.00                0.00   \n",
      "4590           0.00            0.00              0.00                0.00   \n",
      "4591           0.00            0.00              0.00                0.00   \n",
      "4592           2.50            0.00              0.00                0.00   \n",
      "4593           0.00            0.00              0.00                0.00   \n",
      "4594           0.00            0.00              0.00                0.00   \n",
      "4595           0.00            0.00              0.00                0.00   \n",
      "4596           0.00            0.31              0.00                0.00   \n",
      "4597           0.00            0.00              0.00                0.00   \n",
      "4598           0.00            0.00              0.00                0.00   \n",
      "4599           0.32            0.00              0.00                0.00   \n",
      "4600           0.00            0.00              0.00                0.00   \n",
      "\n",
      "      word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
      "0                0.00            0.00  ...        0.000        0.000   \n",
      "1                0.00            0.94  ...        0.000        0.132   \n",
      "2                0.64            0.25  ...        0.010        0.143   \n",
      "3                0.31            0.63  ...        0.000        0.137   \n",
      "4                0.31            0.63  ...        0.000        0.135   \n",
      "5                0.00            0.00  ...        0.000        0.223   \n",
      "6                0.00            0.64  ...        0.000        0.054   \n",
      "7                0.00            0.00  ...        0.000        0.206   \n",
      "8                0.92            0.76  ...        0.000        0.271   \n",
      "9                0.06            0.00  ...        0.040        0.030   \n",
      "10               0.00            1.92  ...        0.000        0.000   \n",
      "11               0.00            0.00  ...        0.022        0.044   \n",
      "12               0.00            0.00  ...        0.000        0.056   \n",
      "13               0.00            0.90  ...        0.000        0.000   \n",
      "14               0.00            0.71  ...        0.000        0.102   \n",
      "15               0.00            1.27  ...        0.000        0.063   \n",
      "16               0.00            0.00  ...        0.000        0.000   \n",
      "17               0.00            0.00  ...        0.000        0.000   \n",
      "18               0.00            0.00  ...        0.000        0.182   \n",
      "19               0.31            0.00  ...        0.000        0.275   \n",
      "20               0.00            0.00  ...        0.000        0.729   \n",
      "21               0.55            0.00  ...        0.042        0.101   \n",
      "22               0.00            0.00  ...        0.404        0.404   \n",
      "23               0.00            0.00  ...        0.000        0.133   \n",
      "24               0.00            0.00  ...        0.000        0.196   \n",
      "25               0.55            0.00  ...        0.042        0.101   \n",
      "26               0.00            0.00  ...        0.000        0.196   \n",
      "27               0.00            0.00  ...        0.000        0.000   \n",
      "28               0.00            0.00  ...        0.000        0.352   \n",
      "29               0.00            0.00  ...        0.000        0.459   \n",
      "...               ...             ...  ...          ...          ...   \n",
      "4571             0.00            0.00  ...        0.000        0.082   \n",
      "4572             0.00            0.00  ...        0.000        0.254   \n",
      "4573             0.00            0.00  ...        0.033        0.033   \n",
      "4574             0.00            0.29  ...        0.000        0.107   \n",
      "4575             0.00            1.38  ...        0.000        0.213   \n",
      "4576             0.00            0.00  ...        0.000        0.131   \n",
      "4577             0.00            0.00  ...        0.000        0.000   \n",
      "4578             0.00            0.00  ...        0.000        0.000   \n",
      "4579             0.00            0.00  ...        0.607        0.064   \n",
      "4580             0.00            0.00  ...        0.000        0.000   \n",
      "4581             0.00            0.00  ...        0.000        0.091   \n",
      "4582             0.00            0.00  ...        0.000        0.000   \n",
      "4583             0.00            0.00  ...        0.000        0.000   \n",
      "4584             0.00            0.00  ...        0.000        0.082   \n",
      "4585             0.00            0.00  ...        0.000        0.625   \n",
      "4586             0.00            0.00  ...        0.000        0.112   \n",
      "4587             0.00            0.00  ...        0.000        0.125   \n",
      "4588             0.00            0.00  ...        0.000        0.000   \n",
      "4589             0.00            0.00  ...        0.000        0.000   \n",
      "4590             0.00            0.00  ...        0.000        0.185   \n",
      "4591             0.00            0.00  ...        0.000        0.000   \n",
      "4592             0.00            0.00  ...        0.000        0.111   \n",
      "4593             0.00            0.00  ...        0.000        0.000   \n",
      "4594             0.00            0.00  ...        0.000        0.630   \n",
      "4595             0.00            0.00  ...        0.000        0.000   \n",
      "4596             0.00            0.00  ...        0.000        0.232   \n",
      "4597             0.00            0.00  ...        0.000        0.000   \n",
      "4598             0.00            0.00  ...        0.102        0.718   \n",
      "4599             0.00            0.00  ...        0.000        0.057   \n",
      "4600             0.00            0.00  ...        0.000        0.000   \n",
      "\n",
      "      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
      "0           0.000        0.778        0.000        0.000   \n",
      "1           0.000        0.372        0.180        0.048   \n",
      "2           0.000        0.276        0.184        0.010   \n",
      "3           0.000        0.137        0.000        0.000   \n",
      "4           0.000        0.135        0.000        0.000   \n",
      "5           0.000        0.000        0.000        0.000   \n",
      "6           0.000        0.164        0.054        0.000   \n",
      "7           0.000        0.000        0.000        0.000   \n",
      "8           0.000        0.181        0.203        0.022   \n",
      "9           0.000        0.244        0.081        0.000   \n",
      "10          0.000        0.462        0.000        0.000   \n",
      "11          0.000        0.663        0.000        0.000   \n",
      "12          0.000        0.786        0.000        0.000   \n",
      "13          0.000        0.000        0.000        0.000   \n",
      "14          0.000        0.357        0.000        0.000   \n",
      "15          0.000        0.572        0.063        0.000   \n",
      "16          0.000        0.428        0.000        0.000   \n",
      "17          0.000        1.975        0.370        0.000   \n",
      "18          0.000        0.455        0.000        0.000   \n",
      "19          0.000        0.055        0.496        0.000   \n",
      "20          0.000        0.729        0.000        0.000   \n",
      "21          0.016        0.250        0.046        0.059   \n",
      "22          0.000        0.809        0.000        0.000   \n",
      "23          0.000        0.667        0.000        0.000   \n",
      "24          0.000        0.392        0.196        0.000   \n",
      "25          0.016        0.250        0.046        0.059   \n",
      "26          0.000        0.392        0.196        0.000   \n",
      "27          0.000        0.368        0.000        0.000   \n",
      "28          0.000        0.352        0.000        0.000   \n",
      "29          0.000        0.091        0.000        0.000   \n",
      "...           ...          ...          ...          ...   \n",
      "4571        0.000        0.082        0.000        0.000   \n",
      "4572        0.000        0.000        0.000        0.000   \n",
      "4573        0.000        0.099        0.000        0.000   \n",
      "4574        0.000        0.000        0.000        0.000   \n",
      "4575        0.000        0.000        0.000        0.000   \n",
      "4576        0.000        0.000        0.000        0.000   \n",
      "4577        0.000        0.000        0.000        0.000   \n",
      "4578        0.145        0.000        0.000        0.000   \n",
      "4579        0.036        0.055        0.000        0.202   \n",
      "4580        0.000        0.000        0.000        0.000   \n",
      "4581        0.000        0.091        0.000        0.000   \n",
      "4582        0.000        0.000        0.000        0.000   \n",
      "4583        0.406        0.000        0.000        0.000   \n",
      "4584        0.000        0.041        0.000        0.000   \n",
      "4585        0.000        0.000        0.000        0.000   \n",
      "4586        0.000        0.000        0.000        0.056   \n",
      "4587        0.000        0.000        0.125        0.000   \n",
      "4588        0.000        0.000        0.000        0.000   \n",
      "4589        0.000        0.000        0.000        0.000   \n",
      "4590        0.000        0.000        0.000        0.092   \n",
      "4591        0.000        0.000        0.000        0.000   \n",
      "4592        0.000        0.000        0.000        0.000   \n",
      "4593        0.000        1.052        0.000        0.000   \n",
      "4594        0.000        0.000        0.000        0.000   \n",
      "4595        0.000        0.000        0.000        0.000   \n",
      "4596        0.000        0.000        0.000        0.000   \n",
      "4597        0.000        0.353        0.000        0.000   \n",
      "4598        0.000        0.000        0.000        0.000   \n",
      "4599        0.000        0.000        0.000        0.000   \n",
      "4600        0.000        0.125        0.000        0.000   \n",
      "\n",
      "      capital_run_length_average  capital_run_length_longest  \\\n",
      "0                          3.756                          61   \n",
      "1                          5.114                         101   \n",
      "2                          9.821                         485   \n",
      "3                          3.537                          40   \n",
      "4                          3.537                          40   \n",
      "5                          3.000                          15   \n",
      "6                          1.671                           4   \n",
      "7                          2.450                          11   \n",
      "8                          9.744                         445   \n",
      "9                          1.729                          43   \n",
      "10                         1.312                           6   \n",
      "11                         1.243                          11   \n",
      "12                         3.728                          61   \n",
      "13                         2.083                           7   \n",
      "14                         1.971                          24   \n",
      "15                         5.659                          55   \n",
      "16                         4.652                          31   \n",
      "17                        35.461                          95   \n",
      "18                         1.320                           4   \n",
      "19                         3.509                          91   \n",
      "20                         3.833                           9   \n",
      "21                         2.569                          66   \n",
      "22                         4.857                          12   \n",
      "23                         1.131                           5   \n",
      "24                         5.466                          22   \n",
      "25                         2.565                          66   \n",
      "26                         5.466                          22   \n",
      "27                         2.611                          12   \n",
      "28                         4.000                          11   \n",
      "29                         2.687                          66   \n",
      "...                          ...                         ...   \n",
      "4571                       1.256                           5   \n",
      "4572                       1.000                           1   \n",
      "4573                       1.489                          11   \n",
      "4574                       1.220                           6   \n",
      "4575                       1.720                          11   \n",
      "4576                       1.488                           5   \n",
      "4577                       1.200                           3   \n",
      "4578                       1.372                           5   \n",
      "4579                       3.766                          43   \n",
      "4580                       1.571                           5   \n",
      "4581                       1.586                           4   \n",
      "4582                       1.266                           3   \n",
      "4583                       1.666                          13   \n",
      "4584                       1.500                           7   \n",
      "4585                       1.375                           4   \n",
      "4586                       1.793                          21   \n",
      "4587                       1.272                           4   \n",
      "4588                       1.111                           2   \n",
      "4589                       1.000                           1   \n",
      "4590                       2.468                          11   \n",
      "4591                       1.000                           1   \n",
      "4592                       1.285                           4   \n",
      "4593                       1.000                           1   \n",
      "4594                       1.727                           5   \n",
      "4595                       1.000                           1   \n",
      "4596                       1.142                           3   \n",
      "4597                       1.555                           4   \n",
      "4598                       1.404                           6   \n",
      "4599                       1.147                           5   \n",
      "4600                       1.250                           5   \n",
      "\n",
      "      capital_run_length_total  spamclass  \n",
      "0                          278          1  \n",
      "1                         1028          1  \n",
      "2                         2259          1  \n",
      "3                          191          1  \n",
      "4                          191          1  \n",
      "5                           54          1  \n",
      "6                          112          1  \n",
      "7                           49          1  \n",
      "8                         1257          1  \n",
      "9                          749          1  \n",
      "10                          21          1  \n",
      "11                         184          1  \n",
      "12                         261          1  \n",
      "13                          25          1  \n",
      "14                         205          1  \n",
      "15                         249          1  \n",
      "16                         107          1  \n",
      "17                         461          1  \n",
      "18                          70          1  \n",
      "19                         186          1  \n",
      "20                          23          1  \n",
      "21                        2259          1  \n",
      "22                          34          1  \n",
      "23                          69          1  \n",
      "24                          82          1  \n",
      "25                        2258          1  \n",
      "26                          82          1  \n",
      "27                          47          1  \n",
      "28                          36          1  \n",
      "29                         129          1  \n",
      "...                        ...        ...  \n",
      "4571                        98          0  \n",
      "4572                        13          0  \n",
      "4573                       137          0  \n",
      "4574                        61          0  \n",
      "4575                        43          0  \n",
      "4576                        64          0  \n",
      "4577                        24          0  \n",
      "4578                        70          0  \n",
      "4579                      1789          0  \n",
      "4580                        11          0  \n",
      "4581                        46          0  \n",
      "4582                        19          0  \n",
      "4583                        70          0  \n",
      "4584                       123          0  \n",
      "4585                        11          0  \n",
      "4586                       174          0  \n",
      "4587                        28          0  \n",
      "4588                        10          0  \n",
      "4589                        22          0  \n",
      "4590                        79          0  \n",
      "4591                         8          0  \n",
      "4592                        27          0  \n",
      "4593                         6          0  \n",
      "4594                        19          0  \n",
      "4595                        24          0  \n",
      "4596                        88          0  \n",
      "4597                        14          0  \n",
      "4598                       118          0  \n",
      "4599                        78          0  \n",
      "4600                        40          0  \n",
      "\n",
      "[4601 rows x 58 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spamclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "count      4601.000000     4601.000000  ...  4601.000000  4601.000000   \n",
       "mean          0.090067        0.239413  ...     0.038575     0.139030   \n",
       "std           0.278616        0.644755  ...     0.243471     0.270355   \n",
       "min           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "25%           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "50%           0.000000        0.000000  ...     0.000000     0.065000   \n",
       "75%           0.000000        0.160000  ...     0.000000     0.188000   \n",
       "max           5.260000       18.180000  ...     4.385000     9.752000   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.016976     0.269071     0.075811     0.044238   \n",
       "std       0.109394     0.815672     0.245882     0.429342   \n",
       "min       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.315000     0.052000     0.000000   \n",
       "max       4.081000    32.478000     6.003000    19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total    spamclass  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of spam emails in the dataset:  1813\n",
      "number of non-spam emails in the dataset:  2788\n"
     ]
    }
   ],
   "source": [
    "# Counting the spam and ham\n",
    "\n",
    "count_spam = len(data_df[data_df.spamclass == 1])\n",
    "count_ham = len(data_df[data_df.spamclass == 0])\n",
    "\n",
    "print(\"number of spam emails in the dataset: \", count_spam)\n",
    "print(\"number of non-spam emails in the dataset: \", count_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the library to split the dataset into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X (independent variables) and y (dependent variable)\n",
    "\n",
    "X = data_df.loc[:, data_df.columns != \"spamclass\"]\n",
    "y = data_df.loc[:, data_df.columns == \"spamclass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test sets using stratified sampling\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (3680, 57)\n",
      "y_train shape:  (3680, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape:  (921, 57)\n",
      "y_test shape:  (921, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Creating the Random Forest Classifier and training it using the training set\n",
    "\n",
    "random_forest_cf = RandomForestClassifier()\n",
    "\n",
    "random_forest_cf = random_forest_cf.fit(X_train, y_train.spamclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the trained Random Forest classifier to test it using the test data\n",
    "\n",
    "random_forest_cf_predict = random_forest_cf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0\n",
      " 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0\n",
      " 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0\n",
      " 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 0\n",
      " 1 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1\n",
      " 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1\n",
      " 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1\n",
      " 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1\n",
      " 0 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0\n",
      " 1 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1\n",
      " 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(random_forest_cf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9522258414766558\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model - comparing the predicted values from the classifier and actual test class values\n",
    "\n",
    "print(np.mean(random_forest_cf_predict == y_test.spamclass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicts the test results with 94.24 % which is quite good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.79353530e-03 3.80382221e-03 8.96560746e-03 9.04750191e-04\n",
      " 3.28520278e-02 7.58394524e-03 1.02245070e-01 4.29589822e-03\n",
      " 1.41056481e-02 6.32916064e-03 4.39623514e-03 9.26708077e-03\n",
      " 5.43653941e-03 1.06869789e-03 9.28182169e-04 7.33480146e-02\n",
      " 1.41650290e-02 5.13019816e-03 3.37996861e-02 1.37754624e-02\n",
      " 3.80511247e-02 2.37830068e-03 8.33599921e-03 3.74981661e-02\n",
      " 2.46836687e-02 3.90949978e-02 2.18618660e-02 6.26046874e-03\n",
      " 1.59580164e-03 2.01103002e-03 6.35119870e-04 3.17570925e-03\n",
      " 1.73253893e-03 1.75605032e-05 3.66463758e-03 3.28620961e-03\n",
      " 9.68260275e-03 5.36481251e-04 2.66663872e-03 4.56745445e-04\n",
      " 7.20310514e-04 4.27671474e-03 1.22008580e-03 1.93909886e-03\n",
      " 7.88340886e-03 2.10711284e-02 9.39702193e-05 1.21025387e-03\n",
      " 4.62167535e-03 1.06952066e-02 1.16438859e-03 1.22331982e-01\n",
      " 1.41672817e-01 8.15927674e-03 5.06415531e-02 3.69467095e-02\n",
      " 3.05311608e-02]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the feature importances of all the 57 independent variables\n",
    "\n",
    "print(random_forest_cf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the sorted importance set to see which are the most important features\n",
    "\n",
    "importances = random_forest_cf.feature_importances_\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in random_forest_cf.estimators_], axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (feature 52) char_freq_$ (0.141673)\n",
      "2. (feature 51) char_freq_! (0.122332)\n",
      "3. (feature 6) word_freq_remove (0.102245)\n",
      "4. (feature 15) word_freq_free (0.073348)\n",
      "5. (feature 54) capital_run_length_average (0.050642)\n",
      "6. (feature 25) word_freq_hpl (0.039095)\n",
      "7. (feature 20) word_freq_your (0.038051)\n",
      "8. (feature 23) word_freq_money (0.037498)\n",
      "9. (feature 55) capital_run_length_longest (0.036947)\n",
      "10. (feature 18) word_freq_you (0.033800)\n",
      "11. (feature 4) word_freq_our (0.032852)\n",
      "12. (feature 56) capital_run_length_total (0.030531)\n",
      "13. (feature 24) word_freq_hp (0.024684)\n",
      "14. (feature 26) word_freq_george (0.021862)\n",
      "15. (feature 45) word_freq_edu (0.021071)\n",
      "16. (feature 16) word_freq_business (0.014165)\n",
      "17. (feature 8) word_freq_order (0.014106)\n",
      "18. (feature 19) word_freq_credit (0.013775)\n",
      "19. (feature 49) char_freq_( (0.010695)\n",
      "20. (feature 36) word_freq_1999 (0.009683)\n",
      "21. (feature 11) word_freq_will (0.009267)\n",
      "22. (feature 2) word_freq_all (0.008966)\n",
      "23. (feature 22) word_freq_000 (0.008336)\n",
      "24. (feature 53) char_freq_# (0.008159)\n",
      "25. (feature 44) word_freq_re (0.007883)\n",
      "26. (feature 5) word_freq_over (0.007584)\n",
      "27. (feature 9) word_freq_mail (0.006329)\n",
      "28. (feature 27) word_freq_650 (0.006260)\n",
      "29. (feature 12) word_freq_people (0.005437)\n",
      "30. (feature 17) word_freq_email (0.005130)\n",
      "31. (feature 0) word_freq_make (0.004794)\n",
      "32. (feature 48) char_freq_; (0.004622)\n",
      "33. (feature 10) word_freq_receive (0.004396)\n",
      "34. (feature 7) word_freq_internet (0.004296)\n",
      "35. (feature 41) word_freq_meeting (0.004277)\n",
      "36. (feature 1) word_freq_address (0.003804)\n",
      "37. (feature 34) word_freq_85 (0.003665)\n",
      "38. (feature 35) word_freq_technology (0.003286)\n",
      "39. (feature 31) word_freq_857 (0.003176)\n",
      "40. (feature 38) word_freq_pm (0.002667)\n",
      "41. (feature 21) word_freq_font (0.002378)\n",
      "42. (feature 29) word_freq_labs (0.002011)\n",
      "43. (feature 43) word_freq_project (0.001939)\n",
      "44. (feature 32) word_freq_data (0.001733)\n",
      "45. (feature 28) word_freq_lab (0.001596)\n",
      "46. (feature 42) word_freq_original (0.001220)\n",
      "47. (feature 47) word_freq_conference (0.001210)\n",
      "48. (feature 50) char_freq_[ (0.001164)\n",
      "49. (feature 13) word_freq_report (0.001069)\n",
      "50. (feature 14) word_freq_addresses (0.000928)\n",
      "51. (feature 3) word_freq_3d (0.000905)\n",
      "52. (feature 40) word_freq_cs (0.000720)\n",
      "53. (feature 30) word_freq_telnet (0.000635)\n",
      "54. (feature 37) word_freq_parts (0.000536)\n",
      "55. (feature 39) word_freq_direct (0.000457)\n",
      "56. (feature 46) word_freq_table (0.000094)\n",
      "57. (feature 33) word_freq_415 (0.000018)\n"
     ]
    }
   ],
   "source": [
    "# Printing the features with their importances in determining the output class - from highest to lowest\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. (feature %d)\" %(f + 1, indices[f]), X.columns[indices[f]], \"(%f)\" %(importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, these 5 variables are the most important in determining the class:\n",
    "\n",
    "char_freq_!\n",
    "<br>\n",
    "char_freq_$\n",
    "<br>\n",
    "capital_run_length_average\n",
    "<br>\n",
    "word_freq_your\n",
    "<br>\n",
    "word_freq_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
